PRP: Demo Vulnerable AI Application + Strix Security Assessment
1. Goal and Audience
Build a small, intentionally vulnerable AI-powered web application (or an application built with AI assistance) and use Strix to automatically discover, exploit, and report vulnerabilities during development workflows. The demo emphasizes that AI-based applications—whether using AI features or built with AI-generated code—can contain both traditional and AI-specific vulnerabilities that need to be identified early in the development lifecycle.​

Audience: software engineers, security engineers, and architects learning about:
- Security vulnerabilities in AI-powered applications
- Using automated security testing (Strix) in development workflows
- Integrating security testing into local development and CI/CD pipelines
- Identifying both traditional vulnerabilities (SQL injection, XSS, IDOR) and AI-specific vulnerabilities (prompt injection, insecure AI model usage, data leakage in AI pipelines)​

2. High-level Demo Flow
1. **Local Development Setup** (2 minutes)
   - Set up Python virtual environment and install dependencies
   - Start the vulnerable app locally (e.g., `python app.py` or `uvicorn app:app`)
   - App runs on http://localhost:8000

2. **Developer Workflow: Run Strix Locally** (3–5 minutes)
   - Developer writes code (potentially AI-assisted) that introduces vulnerabilities
   - Run Strix against the codebase: `strix --target ./app --instruction "Focus on security vulnerabilities"`
   - Run Strix against the running app: `strix --target http://localhost:8000 --instruction "Test for IDOR, SQL injection, XSS, and AI-specific vulnerabilities"`
   - Review findings before committing code

3. **CI/CD Integration** (2–3 minutes)
   - Show GitHub Actions/GitLab CI workflow that runs Strix on every PR
   - Demonstrate how CI fails when critical vulnerabilities are detected
   - Show how developers can fix issues locally and re-run Strix

4. **Review Findings and Remediation** (5 minutes)
   - Review Strix's findings, PoC exploits, and remediation guidance
   - Map findings back to source code
   - Discuss secure coding patterns

The demo should be runnable end-to-end in 10–15 minutes on a typical developer laptop.

3. Technical Stack
Backend: Python 3.12, FastAPI or Flask (single service, no microservices).​

Frontend: Minimal server-rendered HTML templates (Jinja2) to keep complexity low while still demonstrating client-side issues (XSS).​

Database: SQLite with a simple ORM or hand-written queries (to showcase SQL injection).

AI Integration: Optional LLM API integration (OpenAI, Anthropic, or local model) to demonstrate AI-specific vulnerabilities like prompt injection and insecure AI model usage.

Local Development: Python virtual environment (venv or poetry) for dependency management. App runs directly via `python app.py` or `uvicorn app:app` on http://localhost:8000.

Security testing: Strix open-source agent (strix-agent CLI) installed via pipx, runs from host machine against local app.​

4. Intentional Vulnerabilities
Implement a minimal feature set with a mix of traditional web vulnerabilities and AI-specific vulnerabilities (prefer depth over breadth). Target vulnerabilities:​

**Traditional Vulnerabilities (common in AI-generated code):**

IDOR / Broken Access Control

Example: /users/{id} endpoint allows any logged-in user (or even anonymous) to fetch arbitrary user profiles by changing the ID.​

SQL Injection

Example: search or login endpoint concatenates user input directly into a SQL query against SQLite (no parameterization). Common in AI-generated code that doesn't use parameterized queries.​

Reflected XSS

Example: search or feedback page that reflects unescaped query parameter into HTML output.​

**AI-Specific Vulnerabilities:**

Prompt Injection

Example: Chat or AI-powered search endpoint that passes user input directly to LLM prompts without sanitization, allowing attackers to inject malicious instructions that override system prompts or extract sensitive data.

Insecure AI Model Usage

Example: API keys hardcoded in source code or exposed in environment variables, no rate limiting on AI API calls, insecure model endpoint configuration (HTTP instead of HTTPS, no authentication).

Data Leakage in AI Pipelines

Example: Sensitive user data (PII, credentials) included in prompts sent to LLM APIs, logged in plaintext, or stored in vector databases without proper access controls. User queries containing sensitive information are reflected in responses or logs.

AI-Generated Code Vulnerabilities

Example: Code paths generated by AI that lack proper input validation, authorization checks, or use unsafe string concatenation for SQL queries.

Each vulnerability should be:

Active by default for the demo.

Located in clearly separated modules to discuss SOLID and refactoring into secure code later.​

Clearly documented with notes about how AI-generated code or AI features can introduce these risks.

5. Application Features
Minimal app named "VulnBoard" (or similar) that demonstrates both traditional and AI-specific vulnerabilities. The app can be either:
- An AI-powered application (e.g., chatbot, AI-assisted search, RAG system)
- A regular web application built with AI assistance (showing vulnerabilities AI-generated code might introduce)

Core features:

Anonymous landing page.

Simple login with hard-coded users (e.g., admin, user) stored in the database.

User profile page with IDOR vulnerability.

Search or message board feature with SQL injection and reflected XSS.

AI-powered features (if applicable):
- Chat interface that uses LLM APIs (vulnerable to prompt injection)
- AI-assisted search that passes user queries to LLM (data leakage risk)
- Content generation using AI models (insecure API key usage)

Focus is on clarity and traceability from feature → vulnerability → Strix finding, demonstrating how both traditional vulnerabilities and AI-specific issues can be discovered during development.

6. Project Structure (SOLID-friendly)
Proposed repository layout:

vulnboard/
  app/
    __init__.py
    config.py
    main.py              # FastAPI/Flask setup, route wiring
    routes/
      __init__.py
      auth_routes.py     # Login/logout
      user_routes.py     # User profiles (IDOR)
      search_routes.py   # Search / board (SQLi + XSS)
      ai_routes.py       # AI-powered features (prompt injection, insecure AI usage)
    core/
      db.py              # DB connection and low-level helpers (intentionally misused in some services)
      security.py        # Placeholder for proper security checks (partially unused in vulnerable flows)
      ai_client.py       # AI/LLM client wrapper (intentionally insecure - hardcoded keys, no validation)
    models/
      __init__.py
      user.py            # User entity
      post.py            # Board posts / searchable content
    services/
      auth_service.py    # Auth logic (SRP, DIP)
      user_service.py    # User-related operations, intentionally missing proper authorization in one method
      search_service.py  # Business logic with intentionally unsafe query building
      ai_service.py      # AI service with prompt injection and data leakage vulnerabilities
    templates/
      base.html
      login.html
      profile.html       # Reflects unescaped data
      search.html        # Reflects search query (XSS)
      chat.html          # AI chat interface (prompt injection demo)
    static/
      css/
      js/
  tests/
    test_auth_safe.py
    test_user_service_safe.py
  scripts/
    run_strix_local.sh   # Script to run Strix against local codebase
    run_strix_http.sh    # Script to run Strix against running app
  .github/
    workflows/
      strix-ci.yml       # GitHub Actions workflow for CI integration
  security/
    STRIX_RUN_NOTES.md   # Sample output, curated report for training
  .env.example
  requirements.txt
  README.md
  STRIX_DEMO_INSTRUCTIONS.md

Design choices for SOLID:

Single Responsibility Principle: Each service_* module focuses on one domain (auth, user, search).

Open/Closed & Liskov: Entities in models and service interfaces can be safely extended for “secure version” exercises later.

Interface Segregation & Dependency Inversion: services depend on small core abstractions (e.g., DbClient), but some routes bypass them to introduce vulnerabilities explicitly.

7. Strix Integration Requirements
7.1 Prerequisites
Document prerequisites in STRIX_DEMO_INSTRUCTIONS.md:

Python 3.12+.

pipx install strix-agent (or pip install strix-agent).

Environment variables:

STRIX_LLM (e.g., openai/gpt-4, anthropic/claude-3, or configured local LLM).

LLM_API_KEY (or local model base URL if used).​

7.2 Local Development Workflow
Provide ready-made scripts for developers to run Strix during development:

**Code-focused testing (static analysis):**
```bash
# scripts/run_strix_local.sh
export STRIX_LLM="openai/gpt-4"
export LLM_API_KEY="${LLM_API_KEY}"
strix --target ./app --instruction "Focus on security vulnerabilities: IDOR, SQL injection, XSS, prompt injection, insecure AI usage, and data leakage. Generate clear PoC and remediation steps."
```

**Runtime testing (against running application):**
```bash
# scripts/run_strix_http.sh
# Assumes app is running on http://localhost:8000
export STRIX_LLM="openai/gpt-4"
export LLM_API_KEY="${LLM_API_KEY}"
strix --target http://localhost:8000 --instruction "Prioritize IDOR, SQL injection, XSS, prompt injection, and AI-specific vulnerabilities. Generate clear PoC and remediation steps."
```

These scripts should run without editing once environment variables are set. Developers can run them before committing code to catch vulnerabilities early.

7.3 CI/CD Integration
Provide GitHub Actions workflow example (`.github/workflows/strix-ci.yml`):

```yaml
name: Strix Security Scan

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install Strix
        run: pipx install strix-agent
      
      - name: Run Strix Security Scan
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
        run: |
          strix --target ./app --instruction "Scan for security vulnerabilities. Fail on critical findings." --fail-on-critical
      
      - name: Upload Strix Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: strix-results
          path: agent_runs/
```

Similar GitLab CI configuration should be provided. The CI should fail the build when critical vulnerabilities are found, encouraging developers to fix issues before merging.

7.4 Expected Strix Output
Strix should produce at least:

Confirmed IDOR finding with HTTP PoC.

Confirmed SQL injection finding.

Confirmed reflected XSS finding.

Confirmed prompt injection finding (if AI features are present).

Confirmed insecure AI usage finding (hardcoded keys, insecure endpoints).

Findings should be written to `agent_runs/<run-name>` folder, and paths documented in the demo instructions. CI runs should produce artifacts that can be reviewed in the PR/MR interface.​

8. Demo Narrative and Talking Points
Include a short narrative in STRIX_DEMO_INSTRUCTIONS.md:

**Intro (1 minute)**

Explain that this is an intentionally vulnerable application (either AI-powered or built with AI assistance) designed to demonstrate how AI-based applications can contain both traditional and AI-specific vulnerabilities. Emphasize the importance of security testing during development, not just in production.

**Local Development Workflow (3–4 minutes)**

1. **Set up and run the app locally:**
   - Show Python virtual environment setup
   - Install dependencies and start the app: `python app.py` or `uvicorn app:app`
   - App runs on http://localhost:8000

2. **Developer writes code (potentially AI-assisted):**
   - Show a code snippet that introduces a vulnerability (e.g., SQL injection, prompt injection)
   - Explain that AI-generated code can introduce these issues if not properly reviewed

3. **Run Strix locally before committing:**
   - Execute `scripts/run_strix_local.sh` to scan the codebase
   - Show that Strix identifies vulnerabilities immediately
   - Demonstrate how developers can catch issues before they reach the repository

**CI/CD Integration (2–3 minutes)**

1. **Show CI workflow:**
   - Display the GitHub Actions workflow file
   - Explain how Strix runs automatically on every PR
   - Show how CI fails when critical vulnerabilities are detected

2. **Demonstrate blocking behavior:**
   - Create a PR with vulnerable code
   - Show CI failing with Strix findings
   - Explain how this prevents vulnerable code from being merged

**Review Findings (5 minutes)**

1. **Examine Strix output:**
   - Open one vulnerability finding (e.g., prompt injection or SQL injection)
   - Review the PoC exploit that Strix generated
   - Show remediation guidance provided by Strix

2. **Map findings to code:**
   - Map the Strix PoC back to the relevant route and service file
   - Show how the vulnerability was introduced (e.g., unsanitized user input, missing authorization check)

3. **Discuss secure patterns:**
   - Discuss how SOLID practices could help prevent such issues (e.g., consistent authorization layer, query builder abstraction, input validation service)
   - Show how AI-specific vulnerabilities require different mitigations (prompt sanitization, secure API key management, data filtering)

**Next Steps (1–2 minutes)**

1. **Development workflow integration:**
   - Emphasize running Strix locally as part of the development workflow
   - Show how CI integration provides a safety net for the team

2. **Follow-up exercises:**
   - Propose refactoring the app to fix vulnerabilities and comparing Strix results before/after
   - Suggest adding Strix to pre-commit hooks for immediate feedback
   - Discuss how to integrate Strix findings into security review processes

9. Non-Goals and Constraints
No complex frontend frameworks; keep UI minimal.

No third-party authentication or external APIs.

No production use; clearly labelled as a training-only, intentionally vulnerable environment.

All vulnerabilities must be documented clearly, with notes about risks and proper secure patterns (but not fixed by default).​

10. Acceptance Criteria
The demo is considered ready when:

**Local Setup:**
- Python virtual environment setup and `python app.py` (or `uvicorn app:app`) starts the app successfully and it is reachable at http://localhost:8000.

- `scripts/run_strix_local.sh` runs successfully against the codebase and generates at least three confirmed vulnerabilities (mix of traditional: IDOR, SQLi, XSS; and AI-specific: prompt injection, insecure AI usage, or data leakage) with PoCs and remediation notes.

- `scripts/run_strix_http.sh` runs successfully against the running application and generates similar findings.

**CI/CD Integration:**
- GitHub Actions workflow (`.github/workflows/strix-ci.yml`) runs successfully on PRs and fails when critical vulnerabilities are detected.

- CI artifacts (Strix findings) are uploaded and accessible for review.

**Documentation and Usability:**
- A new instructor can follow `STRIX_DEMO_INSTRUCTIONS.md` and complete the whole demo (local setup, running Strix, reviewing findings, CI integration) in under 20 minutes on a fresh machine with only Python 3.12+ and pipx installed.

- Codebase structure reflects SOLID principles sufficiently to support "secure refactor" exercises later.

- All vulnerabilities are clearly documented with notes about risks and proper secure patterns.