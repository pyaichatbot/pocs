# RAG Service Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# Vector Database Configuration
# =============================================================================
# Repository type: "pixeltable", "chromadb", "pgvector", or "cosmosdb"
REPOSITORY_TYPE=chromadb

# Pixeltable Configuration (if using REPOSITORY_TYPE=pixeltable)
PIXELTABLE_CONNECTION=sqlite:///./.pixeltable/metadata.db
PIXELTABLE_MEDIA_DIR=/app/data/pixeltable

# ChromaDB Configuration (if using REPOSITORY_TYPE=chromadb)
# For local persistent storage (standalone mode):
CHROMADB_PATH=/app/data/chromadb
# For ChromaDB server mode (recommended for Docker):
CHROMADB_HOST=chromadb
CHROMADB_PORT=8000

# PostgreSQL/pgvector Configuration (if using REPOSITORY_TYPE=pgvector)
POSTGRES_CONNECTION_STRING=postgresql://raguser:ragpass@postgres:5432/ragdb
POSTGRES_USER=raguser
POSTGRES_PASSWORD=ragpass
POSTGRES_DB=ragdb

# Cosmos DB Configuration (if using REPOSITORY_TYPE=cosmosdb)
COSMOS_ENDPOINT=
COSMOS_KEY=

# =============================================================================
# Embedding Configuration
# =============================================================================
# Embedding model identifier. Options: "intfloat/e5-small-v2", "all-MiniLM-L6-v2", "intfloat/e5-large-v2", etc.
EMBEDDING_MODEL_ID=intfloat/e5-small-v2

# =============================================================================
# Search Configuration
# =============================================================================
# Maximum number of chunks to return per query
MAX_CHUNKS=5
# Maximum words per chunk
CHUNK_MAX_WORDS=300
# Overlap words between chunks
CHUNK_OVERLAP_WORDS=50

# Reranking Configuration
# Enable cross-encoder reranking for better search results
RERANKER_ENABLED=false
# Reranker model identifier
RERANKER_MODEL_ID=cross-encoder/ms-marco-MiniLM-L-6-v2

# =============================================================================
# Parallel Processing
# =============================================================================
# Number of parallel workers for file processing (set to 1 to disable)
MAX_WORKERS=4
# Batch size for document upserts
BATCH_SIZE=100

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# LLM Provider: "anthropic" or "azure" (leave empty to disable LLM, will return contexts only)
LLM_PROVIDER=

# Anthropic Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT_NAME=

# =============================================================================
# ChromaDB Server Configuration (optional, if using ChromaDB server mode)
# =============================================================================
CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.token_authn.TokenAuthenticationServerProvider
CHROMA_SERVER_AUTHN_CREDENTIALS=